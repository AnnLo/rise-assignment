from datasets import load_dataset, DatasetDict
from transformers import BertTokenizerFast

class ProcessData:
    """
    Class for loading, preprocessing and tokenizing the dataset. Aligns named entity labels with tokenized words, which uses word_ids. Therefore, the tokenizer must be a PreTrainedTokenizerFast.
    
    Args:
        system (str): determines which system, A or B, to be tuned
        label2id (dict): mapping between full tag set and ids in dataset
        huggingface_dataset (str): name of huggingface dataset used for tuning
        tokenizer (BertTokenizerFast): pre-trained tokenizer
    """
    def __init__(self, system:str, label2id:dict, huggingface_dataset:str, tokenizer:BertTokenizerFast):
        self.system = system
        self.label2id = label2id
        self.huggingface_datset = huggingface_dataset
        self.label_list = list(self.label2id.keys())
        self.tokenizer = tokenizer
        
    def _handle_labels_subword_tokens(self, word_ids, labels):
        """
        Function that aligns named entities with the tokenized words, since (here) a WordPiece tokenizer splits unknow words into subword units. According to the original BERT-paper https://arxiv.org/pdf/1810.04805.pdf, in this case the representation of the first subtoken is used. To not add more named entities, dummy label for the rest that are not accounted for when calculating the loss. Cross entropy loss in PyTorch ignores index -100  https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html, also tokens with a word_id 'None' will be set to -100 to be automatically and thus ignored. Heavily inspired by https://huggingface.co/docs/transformers/v4.18.0/en/tasks/token_classification.
        
        Args:
            word_ids (list): list of word_ids for the tokenized input
            labels (list): named entity labels corresponding to the input
            
        returns:
            new_labels (list): updated named entity labels aligned with the tokenized input
        """
        new_labels = []
        prev_word_id = None
        for word_id in word_ids:
            if word_id == None:
                # special token
                new_labels.append(-100)
            elif prev_word_id != word_id:
                # not subwords only, label the first token of any given word
                new_labels.append(labels[word_id])

            else:
              # subwords
              # the label for the word has already been appended
              # now append -100
                 new_labels.append(-100)
            prev_word_id = word_id
        return new_labels


    def _tokenize_and_align(self, batch):
        """
        Function that tokenized a batch and then applies alignment.
        
        Args:
            batch (list): list of list of input tokens
        
        returns:
              tokenized_batch (): a tokenized and aligned input batch
        """
        tokenized_batch = self.tokenizer(batch["tokens"], truncation=True, is_split_into_words=True)
        labels = []
        for i, labels_batch in enumerate(batch["ner_tags"]):
            word_ids_batch = tokenized_batch.word_ids(i)
            new_labels_batch = self._handle_labels_subword_tokens(word_ids_batch, labels_batch)
            labels.append(labels_batch)

        tokenized_batch["labels"] = labels

        return tokenized_batch

    def _helper_mapping(self):
        """
        Function that creates label mappings for the desired format in system B. Here we are only interested in the entities containing 'PER', 'LOC', 'DIS', 'ANIM', 'ORG, now all others should be set to 0/O.
        
        returns:
              blabels2id (dict): dictionary mapping between labels and ids
              bid2label (dict): dictionary mapping between ids and labels
        """
        keys = ["O"]
        values = [0]
        for k, v in self.label2id.items():
            if k.split('-')[-1] in ['PER', 'LOC', 'DIS', 'ANIM', 'ORG']:
                if not v in values:
                    keys.append(k)
                    values.append(v)

        blabels2id = {k: v for k, v in zip(keys, values)}
        bid2label = {v: k for k, v in zip(keys, values)}

        return blabels2id, bid2label



    def _map_ner_tags_B(self, example):
        """
        Function that maps the dataset to the setting required for system B.
        
        Args:
            example (): example from the dataset
            
        returns:
            example (): example with updated named entity tags
        """
        blabels2id, bid2label = self._helper_mapping()
        ner_tags = example["ner_tags"]
        mapping_dict= {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 13:9, 14:10}
        new_ner_tags = [mapping_dict[elem] for elem in [0 if not tag in list(bid2label.keys()) else tag for tag in ner_tags]]
        example["ner_tags"] = new_ner_tags
        return example
    
    
    def preprocess_tokenize_dataset(self):
        """
        Function that preprocesses, filters and tokenizes the dataset.
        
        returns:
              self.tokenized_dataset (batch datasetdict?): tokenized dataset
        """
        self.dataset = load_dataset(self.huggingface_datset)
        assert isinstance(self.dataset, DatasetDict), "Not the right type."
        assert list(self.dataset.keys()) == ["train", "validation", "test"], "All splits should be present."
        assert "lang" in self.dataset["train"].features.keys() and "lang" in self.dataset["validation"].features.keys() and "lang" in self.dataset["test"].features.keys(), "Language must be a feature."
        
        all_languages = self.dataset["train"]["lang"]
        all_languages.extend(self.dataset["validation"]["lang"])
        all_languages.extend(self.dataset["test"]["lang"])
        assert "en"  in set(all_languages), "English must be one of the langauges."
        
        # filter out the english part of the dataset
        dataset_en =  self.dataset.filter(lambda example: example["lang"] == "en")
        
        # maybe add this? See if it makes any difference...
        #class_labels = list(self.id2label.values())
        #for ds in self.data_split:
        #    features = self.dataset[ds].features.copy()
        #    features["ner_tags"] = Sequence(feature=ClassLabel(names=class_labels))
        #    self.dataset[ds] = self.dataset[ds].map(features=features)
        
        assert self.system in ["A", "B"], "Not a valid choice."
        
        if self.system == "A":
            # tokenize
            self.tokenized_dataset = dataset_en.map(self._tokenize_and_align, batched=True)
        else:
            self.tokenized_dataset = dataset_en.map(self._map_ner_tags_B).map(self._tokenize_and_align, batched=True)
            
        return self.tokenized_dataset
            
        
        
import numpy as np
import evaluate
from seqeval.metrics import classification_report
import json
from typing import Optional

seqeval = evaluate.load("seqeval")

class Eval:
    """
    A class for calculating evaluation metrics. Uses seqeval https://huggingface.co/spaces/evaluate-metric/seqeval, a python framework for
    sequence labeling evaluation. 
    
    Args: 
        label_list (list): a list of named entity tags (strings format).
        file_save (Optional[str]): optional file name to save output
    """
    def __init__(self, label_list:list):
        self.lable_list = label_list
        
    def metrics(self, eval_predictions):
        """
        Function calculating overall classification metrics on an evaluation dataset. Heavliy inspired by tutorial on token classification https://huggingface.co/docs/transformers/v4.18.0/en/tasks/token_classification and https://huggingface.co/spaces/evaluate-metric/seqeval.
        
        Args:
            eval_predictions (Tuple): the model predictions (logits, and labels) on an evaluation dataset.
        """
        logits, labels = eval_predictions
        predictions = np.argmax(logits, axis=-1)

        # predictions when not ignore
        # indexes for the label list correspond to predicted labels for non-ignore tokens
        
        actual_predictions = [[self.lable_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]
        actual_labels = [[self.lable_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]
        results = seqeval.compute(predictions=actual_predictions, references=actual_labels)

        result_dict = {"precision": results["overall_precision"],
            "recall": results["overall_recall"],
            "f1": results["overall_f1"],
            "accuracy": results["overall_accuracy"],}
        
        print(result_dict)
        
        return result_dict
                
          


    def individual_tag_metrics(self, eval_predictions):
        """
        Function calculating per tag classification metrics and averages.
        
        Args:
            test_prediction (Tuple): the model predictions (logits, and labels) on an evaluation dataset.
        """

        logits, labels, _ = eval_predictions # obs, also returns metrics apparently
        predictions = np.argmax(logits, axis=-1)

        # predictions when not ignore
        # indexes for the label list correspond to predicted labels for non-ignore tokens
        
        actual_predictions = [[self.lable_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]
        actual_labels = [[self.lable_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]

        print(classification_report(actual_predictions, actual_labels))

        
class TagMapping:
    """
    Class for named entity tag-to-id mapping, takes the original full tag set as input and either returns that and the id2label mapping or the updated versions for system B.
    
    Args:
        system (str): determines whether system A or B is considered
    """
    def __init__(self, system:str):
        self.system = system
        # the original tagset:
        self.label2id = {"O": 0,
                       "B-PER": 1,
                        "I-PER": 2,
                        "B-ORG": 3,
                        "I-ORG": 4,
                        "B-LOC": 5,
                        "I-LOC": 6,
                        "B-ANIM": 7,
                        "I-ANIM": 8,
                        "B-BIO": 9,
                        "I-BIO": 10,
                        "B-CEL": 11,
                        "I-CEL": 12,
                        "B-DIS": 13,
                        "I-DIS": 14,
                        "B-EVE": 15,
                        "I-EVE": 16,
                        "B-FOOD": 17,
                        "I-FOOD": 18,
                        "B-INST": 19,
                        "I-INST": 20,
                        "B-MEDIA": 21,
                        "I-MEDIA": 22,
                        "B-MYTH": 23,
                        "I-MYTH": 24,
                        "B-PLANT": 25,
                        "I-PLANT": 26,
                        "B-TIME": 27,
                        "I-TIME": 28,
                        "B-VEHI": 29,
                        "I-VEHI": 30}
        
        
    def _helper_mapping(self):
        """
        Function that creates label mappings for the desired format in system B. Here we are only interested in the entities containing 'PER', 'LOC', 'DIS', 'ANIM', 'ORG, now all others should be set to 0/O.
        
        returns:
              blabels2id (dict): dictionary mapping between labels and ids
              bid2label (dict): dictionary mapping between ids and labels
        """
        keys = ["O"]
        values = [0]
        for k, v in self.label2id.items():
            if k.split('-')[-1] in ['PER', 'LOC', 'DIS', 'ANIM', 'ORG']:
                if not v in values:
                    keys.append(k)
                    values.append(v)

        blabels2id = {k: v for k, v in zip(keys, values)}
        bid2label = {v: k for k, v in zip(keys, values)}

        return blabels2id, bid2label

    def _label_id_mapping_sys_B(self):
        """
        Function that creates labe2id and id2label dict for system B.
        
        returns:
              label2id_B (dict): label to id mapping dict
              id2label_B (dict): id to label mapping dict
        """
        blabels2id, bid2label = self._helper_mapping()
        # map to proper indexing
        mapping_dict= {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 13:9, 14:10}

        label2id_B = {k:mapping_dict[v] for k, v in blabels2id.items()}
        id2label_B = {v:k for k, v in label2id_B.items()}
        return label2id_B, id2label_B
    
    def label2id_id2label(self):
        """
        Function that created the label to id and id to lable mapping dicts for system A and B.
        
        returns:
              self.label2id (dict): label to id mapping dict
              self.id2label (dict): id to label mapping dict    
        """
        assert self.system in ["A", "B"], "Not a valid choice."
        
        
        if self.system == "A":
            id2label = {v:k for k, v in self.label2id.items()}
            self.id2label = id2label
        else:
            self.label2id, self.id2label = self._label_id_mapping_sys_B()
        
        return self.label2id, self.id2label
            